Data shape =  (7613, 5)
Corpus created successfully
0            deed reason earthquak may allah forgiv us
1                 forest fire near la rong sask canada
2    resid ask shelter place notifi offic evacu she...
3          peopl receiv wildfir evacu order california
4    got sent photo rubi alaska smoke wildfir pour ...
5    rockyfir updat california hwi close direct due...
6    flood disast heavi rain caus flash flood stree...
7                               top hill see fire wood
8               emerg evacu happen build across street
9                             afraid tornado come area
Name: 0, dtype: object
embedding matrix shape -> (18888, 200)
example: word 'tornado' has index of -> 322
[ 3.46149993e-03 -1.59089994e-02 -1.25399995e+00 -5.07409990e-01
  1.44999996e-01  2.48479992e-02  3.39130014e-01 -4.16860014e-01
 -8.68860036e-02  1.24159999e-01  5.84330000e-02  4.37079996e-01
 -2.04630002e-01  5.08960001e-02  2.14330003e-01  1.71979994e-01
  4.21490014e-01  3.73030007e-01  2.07220003e-01 -3.08899999e-01
 -1.93489999e-01  2.85230011e-01 -7.99010023e-02 -2.23030001e-01
  5.69869995e-01  3.41879994e-01 -1.02999997e+00  8.75300020e-02
 -6.31030023e-01  1.43460006e-01 -5.52779973e-01  2.86269993e-01
  4.44420010e-01  2.29380000e-02  2.27929994e-01  1.60820007e-01
 -1.15880001e+00  2.25040000e-02 -4.40950006e-01  6.97380006e-01
 -1.10930003e-01 -1.43130004e-01 -5.65620005e-01 -6.01859987e-01
  4.35920000e-01  6.73910022e-01 -1.62410006e-01 -5.15479982e-01
  2.60399997e-01  8.51470008e-02  5.38309991e-01  2.50860006e-01
  3.40119988e-01  3.92870009e-01 -3.21790010e-01 -7.76000023e-02
 -3.53179991e-01  1.55100003e-01  2.41640002e-01  4.57560003e-01
  6.60329998e-01  1.24389994e+00  3.74269992e-01  4.06359993e-02
  3.20809990e-01  5.62489986e-01  3.79559994e-01  1.05520003e-01
 -3.52380008e-01 -1.65030003e-01  1.85509995e-01  6.38970017e-01
 -3.21410000e-01 -6.44110024e-01  3.43140006e-01  2.99549997e-01
 -6.60210013e-01 -2.45030001e-01  4.99170005e-01  1.47480005e-03
  7.85279989e-01  2.30680004e-01  2.57180005e-01  7.34969974e-01
  4.02610004e-01 -5.17960012e-01 -1.34009998e-02 -9.26069990e-02
 -1.69770002e-01  6.86760008e-01 -2.68110007e-01  2.50630006e-02
  1.64250001e-01 -7.53059983e-01 -3.90899986e-01  2.14980006e-01
 -4.73980010e-02 -3.34960014e-01  5.19220009e-02  6.69730008e-01
 -1.30319998e-01  6.94190025e-01  4.71280009e-01  2.71959994e-02
  3.02199990e-01 -2.76769996e-01  2.19699999e-04 -2.10299999e-01
  1.02939999e+00  3.64549994e-01  5.44070005e-01  5.23180008e-01
 -3.73540014e-01  3.06629986e-01  6.70099974e-01  2.64810007e-02
  1.06959999e-01 -2.93130010e-01 -3.49730015e-01 -3.22539985e-01
 -7.07350016e-01  1.97219998e-01 -2.35300004e-01  6.23390019e-01
 -9.34889972e-01  6.62919998e-01  4.57320005e-01 -9.79010016e-02
  1.07340002e+00  6.59659982e-01  6.51719987e-01 -5.05450010e-01
  4.00619991e-02  6.85470030e-02 -5.91019988e-02 -1.59549996e-01
  5.85269988e-01  2.71589998e-02 -2.71299988e-01 -1.45640001e-01
  5.98569989e-01 -2.14049995e-01 -3.20309997e-01  6.85299993e-01
 -6.29410028e-01 -3.99540007e-01 -3.12730014e-01 -3.15239996e-01
  4.45259996e-02 -8.71720016e-01  1.58280000e-01  4.15619999e-01
 -2.27710009e+00 -4.25830007e-01 -1.65360004e-01 -1.11870003e+00
  6.57880008e-01  1.93290003e-02  7.87750006e-01 -3.63150015e-02
  1.26920000e-01 -9.95770022e-02 -7.38979995e-01  7.68999994e-01
  2.80770004e-01  1.73130006e-01 -3.53510007e-02 -1.04530001e+00
  1.52319998e-01 -8.53060007e-01 -3.80030006e-01 -6.58219993e-01
 -8.35789979e-01 -1.75109995e-03  3.70150000e-01 -3.53139997e-01
  2.28530005e-01 -3.62289995e-01 -4.32090014e-01  2.48410001e-01
  5.00410020e-01 -5.14380001e-02  3.30209993e-02  1.25200003e-01
 -9.08399969e-02 -1.05800003e-01  2.06940006e-02 -2.47909993e-01
 -5.86210012e-01  6.78520024e-01  4.20010000e-01  2.95760006e-01
  1.53919995e-01 -7.70110011e-01 -5.32019973e-01 -1.69970006e-01
  2.79460013e-01  3.58489990e-01  2.26889998e-01  4.07669991e-02]
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 50, 200)           3777600   
_________________________________________________________________
spatial_dropout1d (SpatialDr (None, 50, 200)           0         
_________________________________________________________________
gru (GRU)                    (None, 100)               90600     
_________________________________________________________________
dense (Dense)                (None, 1)                 101       
=================================================================
Total params: 3,868,301
Trainable params: 90,701
Non-trainable params: 3,777,600
_________________________________________________________________
Shape of train (6090, 50)
Shape of Validation  (1523, 50)
Train on 6090 samples, validate on 1523 samples
Epoch 1/30
6090/6090 - 123s - loss: 0.7491 - accuracy: 0.5864 - val_loss: 0.6841 - val_accuracy: 0.5686
Epoch 2/30
6090/6090 - 120s - loss: 0.8676 - accuracy: 0.5772 - val_loss: 0.6878 - val_accuracy: 0.5686
Epoch 3/30
6090/6090 - 120s - loss: 0.6684 - accuracy: 0.5938 - val_loss: 0.6873 - val_accuracy: 0.5686
Epoch 4/30
6090/6090 - 119s - loss: 0.6368 - accuracy: 0.6791 - val_loss: 0.6873 - val_accuracy: 0.5686
Epoch 5/30
6090/6090 - 120s - loss: 0.5869 - accuracy: 0.7202 - val_loss: 0.6826 - val_accuracy: 0.5686
Epoch 6/30
6090/6090 - 119s - loss: 0.6033 - accuracy: 0.7294 - val_loss: 0.6853 - val_accuracy: 0.5686
Epoch 7/30
6090/6090 - 118s - loss: 0.5611 - accuracy: 0.7494 - val_loss: 0.6884 - val_accuracy: 0.6415
Epoch 8/30
6090/6090 - 116s - loss: 0.5764 - accuracy: 0.7511 - val_loss: 0.6882 - val_accuracy: 0.7584
Epoch 9/30
6090/6090 - 116s - loss: 0.5754 - accuracy: 0.7473 - val_loss: 0.6934 - val_accuracy: 0.4320
Epoch 10/30
6090/6090 - 116s - loss: 0.6266 - accuracy: 0.7438 - val_loss: 0.7177 - val_accuracy: 0.4314
Epoch 11/30
6090/6090 - 116s - loss: 0.6218 - accuracy: 0.7381 - val_loss: 0.7052 - val_accuracy: 0.4314
Epoch 12/30
6090/6090 - 116s - loss: 0.5483 - accuracy: 0.7652 - val_loss: 0.7196 - val_accuracy: 0.4314
Epoch 13/30
6090/6090 - 116s - loss: 0.5920 - accuracy: 0.7640 - val_loss: 0.7310 - val_accuracy: 0.4314
Epoch 14/30
6090/6090 - 116s - loss: 0.5272 - accuracy: 0.7681 - val_loss: 0.7053 - val_accuracy: 0.4314
Epoch 15/30
6090/6090 - 116s - loss: 0.5445 - accuracy: 0.7670 - val_loss: 0.7337 - val_accuracy: 0.4314
Epoch 16/30
6090/6090 - 115s - loss: 0.5906 - accuracy: 0.7670 - val_loss: 0.7325 - val_accuracy: 0.4314
Epoch 17/30
6090/6090 - 116s - loss: 0.5881 - accuracy: 0.7381 - val_loss: 0.7591 - val_accuracy: 0.4314
Epoch 18/30
6090/6090 - 117s - loss: 0.5442 - accuracy: 0.7585 - val_loss: 0.7289 - val_accuracy: 0.4314
Epoch 19/30
6090/6090 - 118s - loss: 0.5331 - accuracy: 0.7678 - val_loss: 0.6987 - val_accuracy: 0.4458
Epoch 20/30
6090/6090 - 118s - loss: 0.5251 - accuracy: 0.7737 - val_loss: 0.7150 - val_accuracy: 0.4320
Epoch 21/30
6090/6090 - 118s - loss: 0.5403 - accuracy: 0.7760 - val_loss: 0.7629 - val_accuracy: 0.4314
Epoch 22/30
6090/6090 - 118s - loss: 0.6115 - accuracy: 0.7765 - val_loss: 0.7580 - val_accuracy: 0.4314
Epoch 23/30
6090/6090 - 121s - loss: 0.5133 - accuracy: 0.7837 - val_loss: 0.7501 - val_accuracy: 0.4314
Epoch 24/30
6090/6090 - 119s - loss: 0.5218 - accuracy: 0.7839 - val_loss: 0.7575 - val_accuracy: 0.4314
Epoch 25/30
6090/6090 - 117s - loss: 0.5263 - accuracy: 0.7788 - val_loss: 0.7543 - val_accuracy: 0.4314
Epoch 26/30
6090/6090 - 117s - loss: 0.5882 - accuracy: 0.7857 - val_loss: 0.7230 - val_accuracy: 0.4334
Epoch 27/30
6090/6090 - 117s - loss: 0.4843 - accuracy: 0.7934 - val_loss: 0.7637 - val_accuracy: 0.4314
Epoch 28/30
6090/6090 - 117s - loss: 0.4954 - accuracy: 0.7934 - val_loss: 0.6942 - val_accuracy: 0.5010
Epoch 29/30
6090/6090 - 117s - loss: 0.5065 - accuracy: 0.7890 - val_loss: 0.7670 - val_accuracy: 0.4314
Epoch 30/30
6090/6090 - 117s - loss: 0.5511 - accuracy: 0.8025 - val_loss: 0.7122 - val_accuracy: 0.4636
