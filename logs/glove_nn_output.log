Data shape =  (7613, 5)
Corpus created successfully
0            deed reason earthquak may allah forgiv us
1                 forest fire near la rong sask canada
2    resid ask shelter place notifi offic evacu she...
3          peopl receiv wildfir evacu order california
4    got sent photo rubi alaska smoke wildfir pour ...
5    rockyfir updat california hwi close direct due...
6    flood disast heavi rain caus flash flood stree...
7                               top hill see fire wood
8               emerg evacu happen build across street
9                             afraid tornado come area
Name: 0, dtype: object
embedding matrix shape -> (18888, 25)
example: word 'tornado' has index of -> 322
[-0.39229    -0.081708   -0.023277    0.079867   -0.51217002 -0.045167
  0.99607003 -0.26958999  0.50896001  0.49594     0.34323999 -0.029634
 -1.60870004  1.39769995  1.33539999 -0.16018     0.072705    0.7234
  0.39535001 -0.73582    -0.35319     0.29728001  1.32939994 -1.17709994
  0.22761001]
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 50, 25)            472200    
_________________________________________________________________
flatten (Flatten)            (None, 1250)              0         
_________________________________________________________________
dense (Dense)                (None, 1000)              1251000   
_________________________________________________________________
dense_1 (Dense)              (None, 500)               500500    
_________________________________________________________________
dense_2 (Dense)              (None, 50)                25050     
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 51        
=================================================================
Total params: 2,248,801
Trainable params: 1,776,601
Non-trainable params: 472,200
_________________________________________________________________
[0 0 1 ... 1 1 1] (6090,)
Shape of train (6090, 50)
Shape of Validation  (1523, 50)
Train on 6090 samples, validate on 1523 samples
Epoch 1/10
6090/6090 - 22s - loss: 0.6995 - accuracy: 0.6576 - val_loss: 0.5798 - val_accuracy: 0.7288
Epoch 2/10
6090/6090 - 23s - loss: 0.5492 - accuracy: 0.7673 - val_loss: 0.6651 - val_accuracy: 0.7689
Epoch 3/10
6090/6090 - 22s - loss: 0.4755 - accuracy: 0.8062 - val_loss: 0.6438 - val_accuracy: 0.7682
Epoch 4/10
6090/6090 - 22s - loss: 0.3892 - accuracy: 0.8429 - val_loss: 0.7653 - val_accuracy: 0.7754
Epoch 5/10
6090/6090 - 23s - loss: 0.3402 - accuracy: 0.8729 - val_loss: 0.8977 - val_accuracy: 0.7781
Epoch 6/10
6090/6090 - 22s - loss: 0.2836 - accuracy: 0.9051 - val_loss: 0.9736 - val_accuracy: 0.7689
Epoch 7/10
6090/6090 - 23s - loss: 0.2392 - accuracy: 0.9276 - val_loss: 0.9989 - val_accuracy: 0.7656
Epoch 8/10
6090/6090 - 23s - loss: 0.2108 - accuracy: 0.9465 - val_loss: 1.0755 - val_accuracy: 0.7708
Epoch 9/10
6090/6090 - 23s - loss: 0.1962 - accuracy: 0.9593 - val_loss: 1.2181 - val_accuracy: 0.7682
Epoch 10/10
6090/6090 - 22s - loss: 0.1825 - accuracy: 0.9695 - val_loss: 1.2337 - val_accuracy: 0.7669
embedding matrix shape -> (18888, 50)
example: word 'tornado' has index of -> 322
[-0.29031     0.45594999 -0.32435    -1.102      -0.53430003 -0.093038
  0.78965998 -0.39019001  0.43114999 -0.93287998  0.72934997  0.13166
 -2.48889995  0.2448      1.04869998  0.91213    -0.057405    0.24284001
  0.30669001 -0.78845     0.078412    0.022086   -0.1338     -0.69725001
  0.10782    -0.25121999 -1.13450003  0.68168998 -0.27509001  1.3549
 -0.47694001  0.1048      1.03170002  0.061478    0.29107001  0.16621
 -1.38909996  0.75727999 -0.41800001 -0.17411    -0.36730999 -0.97115999
  0.24748001 -0.076654   -0.72639     1.06920004 -0.18068001  0.060325
  0.025361    1.26859999]
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 50, 50)            944400    
_________________________________________________________________
flatten_1 (Flatten)          (None, 2500)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 1000)              2501000   
_________________________________________________________________
dense_5 (Dense)              (None, 500)               500500    
_________________________________________________________________
dense_6 (Dense)              (None, 50)                25050     
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 51        
=================================================================
Total params: 3,971,001
Trainable params: 3,026,601
Non-trainable params: 944,400
_________________________________________________________________
[0 0 1 ... 0 1 0] (6090,)
Shape of train (6090, 50)
Shape of Validation  (1523, 50)
Train on 6090 samples, validate on 1523 samples
Epoch 1/10
6090/6090 - 26s - loss: 0.7002 - accuracy: 0.6934 - val_loss: 0.5889 - val_accuracy: 0.7242
Epoch 2/10
6090/6090 - 25s - loss: 0.4937 - accuracy: 0.8072 - val_loss: 0.6615 - val_accuracy: 0.7610
Epoch 3/10
6090/6090 - 26s - loss: 0.4115 - accuracy: 0.8404 - val_loss: 0.8403 - val_accuracy: 0.7708
Epoch 4/10
6090/6090 - 26s - loss: 0.3365 - accuracy: 0.8806 - val_loss: 1.0693 - val_accuracy: 0.7643
Epoch 5/10
6090/6090 - 25s - loss: 0.2736 - accuracy: 0.9190 - val_loss: 1.2276 - val_accuracy: 0.7603
Epoch 6/10
6090/6090 - 26s - loss: 0.2239 - accuracy: 0.9430 - val_loss: 1.2822 - val_accuracy: 0.7663
Epoch 7/10
6090/6090 - 26s - loss: 0.1875 - accuracy: 0.9677 - val_loss: 1.4301 - val_accuracy: 0.7669
Epoch 8/10
6090/6090 - 26s - loss: 0.1722 - accuracy: 0.9744 - val_loss: 1.6383 - val_accuracy: 0.7525
Epoch 9/10
6090/6090 - 26s - loss: 0.1519 - accuracy: 0.9816 - val_loss: 1.5746 - val_accuracy: 0.7669
Epoch 10/10
6090/6090 - 26s - loss: 0.1567 - accuracy: 0.9834 - val_loss: 1.7028 - val_accuracy: 0.7663
embedding matrix shape -> (18888, 100)
example: word 'tornado' has index of -> 322
[ 1.12609994  1.33589995 -0.54071999 -0.56663001  0.87344998 -0.29416999
  0.74702001  0.34913    -0.014052   -0.26642001  1.0618      0.81356001
 -1.87979996  0.12581     0.73681003 -0.51569998  0.84859997 -0.2271
  0.14514001 -0.010658   -0.64598    -0.37512001 -0.77025002  0.098505
  0.92790997 -0.059978   -1.1566      0.52964002 -0.11316     0.64412999
  0.052537    0.16043     0.81518     0.25766    -0.28977001  0.79504001
 -0.036734   -0.34006    -0.20088001  0.20534    -0.50471997  0.0071002
 -0.16076    -0.66408002 -0.074128    0.69032001  0.26548001  0.69120002
 -0.38062999  0.082889    0.54912001  0.40722999  0.36107001 -0.15676001
  0.14453     0.29721001 -0.41839999  0.47850001 -0.29831001 -0.61129999
 -0.60922998  1.44889998 -0.69287002  0.57797998  0.55926001 -0.12206
  0.39901    -0.17494     0.17563    -1.12440002  0.81532001  0.19357
  0.24998    -0.076736    0.017033   -0.17752001 -0.051373    0.13276
  0.45021001 -0.50568998  1.16279995 -0.65012997  0.80125999  0.63212001
  0.2615     -0.42930001  0.39184999 -0.50866002 -0.20945001  0.19335
  0.080099    0.28027001  0.095866   -0.19065    -0.1067      0.37322
 -0.17718001 -0.1584     -0.24985    -0.16311   ]
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, 50, 100)           1888800   
_________________________________________________________________
flatten_2 (Flatten)          (None, 5000)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 1000)              5001000   
_________________________________________________________________
dense_9 (Dense)              (None, 500)               500500    
_________________________________________________________________
dense_10 (Dense)             (None, 50)                25050     
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 51        
=================================================================
Total params: 7,415,401
Trainable params: 5,526,601
Non-trainable params: 1,888,800
_________________________________________________________________
[0 0 1 ... 0 1 0] (6090,)
Shape of train (6090, 50)
Shape of Validation  (1523, 50)
Train on 6090 samples, validate on 1523 samples
Epoch 1/10
6090/6090 - 34s - loss: 0.6257 - accuracy: 0.7033 - val_loss: 0.6177 - val_accuracy: 0.7426
Epoch 2/10
6090/6090 - 40s - loss: 0.4571 - accuracy: 0.8233 - val_loss: 0.6873 - val_accuracy: 0.7551
Epoch 3/10
6090/6090 - 40s - loss: 0.3414 - accuracy: 0.8826 - val_loss: 0.9085 - val_accuracy: 0.7636
Epoch 4/10
6090/6090 - 33s - loss: 0.2789 - accuracy: 0.9238 - val_loss: 1.1785 - val_accuracy: 0.7452
Epoch 5/10
6090/6090 - 32s - loss: 0.2260 - accuracy: 0.9583 - val_loss: 1.3770 - val_accuracy: 0.7485
Epoch 6/10
6090/6090 - 33s - loss: 0.2072 - accuracy: 0.9724 - val_loss: 1.4008 - val_accuracy: 0.7485
Epoch 7/10
6090/6090 - 33s - loss: 0.1963 - accuracy: 0.9783 - val_loss: 1.5628 - val_accuracy: 0.7472
Epoch 8/10
6090/6090 - 32s - loss: 0.1963 - accuracy: 0.9834 - val_loss: 1.6791 - val_accuracy: 0.7400
Epoch 9/10
6090/6090 - 32s - loss: 0.1951 - accuracy: 0.9837 - val_loss: 1.8758 - val_accuracy: 0.7472
Epoch 10/10
6090/6090 - 32s - loss: 0.1896 - accuracy: 0.9836 - val_loss: 1.8208 - val_accuracy: 0.7492
embedding matrix shape -> (18888, 200)
example: word 'tornado' has index of -> 322
[ 3.46149993e-03 -1.59089994e-02 -1.25399995e+00 -5.07409990e-01
  1.44999996e-01  2.48479992e-02  3.39130014e-01 -4.16860014e-01
 -8.68860036e-02  1.24159999e-01  5.84330000e-02  4.37079996e-01
 -2.04630002e-01  5.08960001e-02  2.14330003e-01  1.71979994e-01
  4.21490014e-01  3.73030007e-01  2.07220003e-01 -3.08899999e-01
 -1.93489999e-01  2.85230011e-01 -7.99010023e-02 -2.23030001e-01
  5.69869995e-01  3.41879994e-01 -1.02999997e+00  8.75300020e-02
 -6.31030023e-01  1.43460006e-01 -5.52779973e-01  2.86269993e-01
  4.44420010e-01  2.29380000e-02  2.27929994e-01  1.60820007e-01
 -1.15880001e+00  2.25040000e-02 -4.40950006e-01  6.97380006e-01
 -1.10930003e-01 -1.43130004e-01 -5.65620005e-01 -6.01859987e-01
  4.35920000e-01  6.73910022e-01 -1.62410006e-01 -5.15479982e-01
  2.60399997e-01  8.51470008e-02  5.38309991e-01  2.50860006e-01
  3.40119988e-01  3.92870009e-01 -3.21790010e-01 -7.76000023e-02
 -3.53179991e-01  1.55100003e-01  2.41640002e-01  4.57560003e-01
  6.60329998e-01  1.24389994e+00  3.74269992e-01  4.06359993e-02
  3.20809990e-01  5.62489986e-01  3.79559994e-01  1.05520003e-01
 -3.52380008e-01 -1.65030003e-01  1.85509995e-01  6.38970017e-01
 -3.21410000e-01 -6.44110024e-01  3.43140006e-01  2.99549997e-01
 -6.60210013e-01 -2.45030001e-01  4.99170005e-01  1.47480005e-03
  7.85279989e-01  2.30680004e-01  2.57180005e-01  7.34969974e-01
  4.02610004e-01 -5.17960012e-01 -1.34009998e-02 -9.26069990e-02
 -1.69770002e-01  6.86760008e-01 -2.68110007e-01  2.50630006e-02
  1.64250001e-01 -7.53059983e-01 -3.90899986e-01  2.14980006e-01
 -4.73980010e-02 -3.34960014e-01  5.19220009e-02  6.69730008e-01
 -1.30319998e-01  6.94190025e-01  4.71280009e-01  2.71959994e-02
  3.02199990e-01 -2.76769996e-01  2.19699999e-04 -2.10299999e-01
  1.02939999e+00  3.64549994e-01  5.44070005e-01  5.23180008e-01
 -3.73540014e-01  3.06629986e-01  6.70099974e-01  2.64810007e-02
  1.06959999e-01 -2.93130010e-01 -3.49730015e-01 -3.22539985e-01
 -7.07350016e-01  1.97219998e-01 -2.35300004e-01  6.23390019e-01
 -9.34889972e-01  6.62919998e-01  4.57320005e-01 -9.79010016e-02
  1.07340002e+00  6.59659982e-01  6.51719987e-01 -5.05450010e-01
  4.00619991e-02  6.85470030e-02 -5.91019988e-02 -1.59549996e-01
  5.85269988e-01  2.71589998e-02 -2.71299988e-01 -1.45640001e-01
  5.98569989e-01 -2.14049995e-01 -3.20309997e-01  6.85299993e-01
 -6.29410028e-01 -3.99540007e-01 -3.12730014e-01 -3.15239996e-01
  4.45259996e-02 -8.71720016e-01  1.58280000e-01  4.15619999e-01
 -2.27710009e+00 -4.25830007e-01 -1.65360004e-01 -1.11870003e+00
  6.57880008e-01  1.93290003e-02  7.87750006e-01 -3.63150015e-02
  1.26920000e-01 -9.95770022e-02 -7.38979995e-01  7.68999994e-01
  2.80770004e-01  1.73130006e-01 -3.53510007e-02 -1.04530001e+00
  1.52319998e-01 -8.53060007e-01 -3.80030006e-01 -6.58219993e-01
 -8.35789979e-01 -1.75109995e-03  3.70150000e-01 -3.53139997e-01
  2.28530005e-01 -3.62289995e-01 -4.32090014e-01  2.48410001e-01
  5.00410020e-01 -5.14380001e-02  3.30209993e-02  1.25200003e-01
 -9.08399969e-02 -1.05800003e-01  2.06940006e-02 -2.47909993e-01
 -5.86210012e-01  6.78520024e-01  4.20010000e-01  2.95760006e-01
  1.53919995e-01 -7.70110011e-01 -5.32019973e-01 -1.69970006e-01
  2.79460013e-01  3.58489990e-01  2.26889998e-01  4.07669991e-02]
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 50, 200)           3777600   
_________________________________________________________________
flatten_3 (Flatten)          (None, 10000)             0         
_________________________________________________________________
dense_12 (Dense)             (None, 1000)              10001000  
_________________________________________________________________
dense_13 (Dense)             (None, 500)               500500    
_________________________________________________________________
dense_14 (Dense)             (None, 50)                25050     
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 51        
=================================================================
Total params: 14,304,201
Trainable params: 10,526,601
Non-trainable params: 3,777,600
_________________________________________________________________
[1 0 0 ... 1 1 0] (6090,)
Shape of train (6090, 50)
Shape of Validation  (1523, 50)
Train on 6090 samples, validate on 1523 samples
Epoch 1/10
6090/6090 - 48s - loss: 0.6370 - accuracy: 0.7143 - val_loss: 0.6340 - val_accuracy: 0.7459
Epoch 2/10
6090/6090 - 48s - loss: 0.3784 - accuracy: 0.8667 - val_loss: 0.8923 - val_accuracy: 0.7708
Epoch 3/10
6090/6090 - 49s - loss: 0.2868 - accuracy: 0.9256 - val_loss: 1.1901 - val_accuracy: 0.7663
Epoch 4/10
6090/6090 - 83s - loss: 0.2423 - accuracy: 0.9657 - val_loss: 1.2996 - val_accuracy: 0.7420
Epoch 5/10
6090/6090 - 48s - loss: 0.2178 - accuracy: 0.9791 - val_loss: 1.5886 - val_accuracy: 0.7551
Epoch 6/10
6090/6090 - 48s - loss: 0.2181 - accuracy: 0.9828 - val_loss: 1.7108 - val_accuracy: 0.7492
Epoch 7/10
6090/6090 - 50s - loss: 0.2235 - accuracy: 0.9821 - val_loss: 2.4292 - val_accuracy: 0.7387
Epoch 8/10
6090/6090 - 50s - loss: 0.2188 - accuracy: 0.9839 - val_loss: 1.9157 - val_accuracy: 0.7446
Epoch 9/10
6090/6090 - 50s - loss: 0.2140 - accuracy: 0.9836 - val_loss: 2.0832 - val_accuracy: 0.7282
Epoch 10/10
6090/6090 - 49s - loss: 0.2196 - accuracy: 0.9844 - val_loss: 2.1170 - val_accuracy: 0.7393
